// Generated by the protocol buffer compiler.  DO NOT EDIT!
// NO CHECKED-IN PROTOBUF GENCODE
// source: tensorflow/core/protobuf/config.proto
// Protobuf Java Version: 4.28.3

package org.tensorflow.proto;

public interface BatchingOptionsOrBuilder extends
    // @@protoc_insertion_point(interface_extends:tensorflow.BatchingOptions)
    com.google.protobuf.MessageOrBuilder {

  /**
   * <pre>
   * Number of scheduling threads for processing batches of work. Determines
   * the number of batches processed in parallel. This should be roughly in line
   * with the number of TPU cores available.
   * </pre>
   *
   * <code>int32 num_batch_threads = 1;</code>
   * @return The numBatchThreads.
   */
  int getNumBatchThreads();

  /**
   * <pre>
   * The maximum allowed batch size. Can be larger than allowed_batch_sizes to
   * utilize large batch splitting.
   * </pre>
   *
   * <code>int32 max_batch_size = 2;</code>
   * @return The maxBatchSize.
   */
  int getMaxBatchSize();

  /**
   * <pre>
   * Maximum number of microseconds to wait before outputting an incomplete
   * batch.
   * </pre>
   *
   * <code>int32 batch_timeout_micros = 3;</code>
   * @return The batchTimeoutMicros.
   */
  int getBatchTimeoutMicros();

  /**
   * <pre>
   * Optional list of allowed batch sizes. If left empty, does nothing.
   * Otherwise, supplies a list of batch sizes, causing the op to pad batches up
   * to one of those sizes. The entries must increase monotonically, and the
   * final entry must be equal or less than the max_batch_size.
   * </pre>
   *
   * <code>repeated int32 allowed_batch_sizes = 4;</code>
   * @return A list containing the allowedBatchSizes.
   */
  java.util.List<java.lang.Integer> getAllowedBatchSizesList();
  /**
   * <pre>
   * Optional list of allowed batch sizes. If left empty, does nothing.
   * Otherwise, supplies a list of batch sizes, causing the op to pad batches up
   * to one of those sizes. The entries must increase monotonically, and the
   * final entry must be equal or less than the max_batch_size.
   * </pre>
   *
   * <code>repeated int32 allowed_batch_sizes = 4;</code>
   * @return The count of allowedBatchSizes.
   */
  int getAllowedBatchSizesCount();
  /**
   * <pre>
   * Optional list of allowed batch sizes. If left empty, does nothing.
   * Otherwise, supplies a list of batch sizes, causing the op to pad batches up
   * to one of those sizes. The entries must increase monotonically, and the
   * final entry must be equal or less than the max_batch_size.
   * </pre>
   *
   * <code>repeated int32 allowed_batch_sizes = 4;</code>
   * @param index The index of the element to return.
   * @return The allowedBatchSizes at the given index.
   */
  int getAllowedBatchSizes(int index);

  /**
   * <pre>
   * Maximum number of batches enqueued for processing before requests are
   * failed fast.
   * </pre>
   *
   * <code>int32 max_enqueued_batches = 5;</code>
   * @return The maxEnqueuedBatches.
   */
  int getMaxEnqueuedBatches();
}
